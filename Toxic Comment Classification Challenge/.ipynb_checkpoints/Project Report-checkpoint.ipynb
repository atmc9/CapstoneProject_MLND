{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Project\n",
    "Anvesh Tummala    \n",
    "May 20th, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table {\n",
       "        display: inline-block\n",
       "    }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    table {\n",
    "        display: inline-block\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxic Comment Classification  \n",
    "###### Identify and classify toxic online comments\n",
    "\n",
    "# 1. Definition\n",
    "-----------\n",
    "### Project Overview:\n",
    "\n",
    "For a community to get the diverse opinions and feedbacks every individual voice matters a lot. But with increasing number of online threats, hate conversations, sexual abusive comments many people stop expressing themselves in the online communities. Many platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut down user comments. This is a great threat to freedom of expression. \n",
    "\n",
    "The goal of this project is to create a model that is able to detect probability of different levels of toxicity like threats, obscenity, insults, and identity-based hate on any textual comments/posts. This model will helps online communities to create a better monitoring, in-turn creates a better place for productive and respectful conversations. \n",
    "\n",
    "This project is part of Kaggle's, [*Toxic Comment Classification Challenge*](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge). I will be trying to do a multi-labeled classification, that can be able to identify the nature of toxicity (threats, obscenity, insults, identity-based hate) in any text data. This classification problem takes the input training dataset of wiki comments that were hand labeled to different toxic classes and we will train and validate, test the model using different ML and deep-learning techniques learned through out this course.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Problem Statement\n",
    "\n",
    "The goal of this project is to create a multi-headed model that is able to detect probability of different levels of toxicity like threats, obscenity, insults, and identity-based hate on any textual data(comments/posts). This model will helps online communities to create a better monitoring, in-turn creates a better place for productive and respectful conversations. For model creation we will be exploring a lot of Deep learning models and we will have great understanding of performance comparison for text classification.\n",
    "\n",
    "Traditionally identifying the toxic comments is worked as a binary classification problem where they just try to make 2 labels (toxic, non-toxic) more like a sentiment analysis model. Whereas in this project we will be trying to do a multi-labeled classification, that can be able to identify the nature of toxicity (threats, obscenity, insults, identity-based hate). So this is a classification problem that takes the input training dataset of wiki comments that were hand labeled to different toxic classes and we will train a model. Finally we will test the model that takes the test comments and will try to label toxicity in them. I will also try to train ensemble of binary classification models with each class labels as true or false and compare it with single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Inputs\n",
    "\n",
    "As part of Kaggle's Toxic Comment Classification Challenge, Jigsaw and Google together provided a dataset of comments from Wikipediaâ€™s talk page edits. These comments have been labeled by human raters for the following toxic types \"toxic, severe_toxic, obscene, threat, insult, identity_hate\".\n",
    "\n",
    "The dataset includes:\n",
    "* train.csv - the training set, contains 159571 wiki comments with their binary labels\n",
    "* test.csv - the test set, you must predict the toxicity probabilities for 153164 comments. To deter hand labeling, the test set contains some comments which are not included in scoring.\n",
    "\n",
    "From the training dataset, we will be feature engineering and will be considering the features like number of words, parts of speech, number of punctuations, number of upper case words, etc\n",
    "\n",
    "Here is the list of toxic labels and their distribution out of 159571 training samples. From the below diagram the classes are not balanced, so we need to use sampling techniques to overcome this.\n",
    "![Class Label distribution](images/output_17_0.png)\n",
    "\n",
    " We will be using 60/15/25 % slit on training data to get train/validation/testing(as they haven't given labeled testing data). We will also try to use the k-fold split to gain the more training data, not compromising the correctness of model. In the split data sets I will be verifying the distribution of output labels, as that is very crucial for out testing score.  \n",
    "\n",
    "-----------\n",
    "1. [Kaggle, Jigsaw-toxic-comment-classification-challenge-data](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "I will be using the evaluation metric as the mean column-wise ROC AUC. It is the average score of individual AUCs of each predicted column.\n",
    "\n",
    "The possible outcomes of a classification are true positive (TP), false positive (FP), true negative (TN), false negative (FN).\n",
    "\n",
    "* true positive rate: TPR = positives correctly classified / total positives = TP / P\n",
    "* alse positive rate: FPR = negatives incorrectly classified / total negatives = FP / N\n",
    "\n",
    "ROC is a graph over FPR (False positive rate) over X-axis and TPR(True positive rate) over Y-axis.\n",
    "\n",
    "This metric would  a great measure of probabilistic classification among different labels. We will consider each column AUC separately and will average it for our final score. \n",
    "\n",
    "What is my Metrics expectation: AUC of 0.5 like a random guessing, AUC of 1 will be like a perfect classifier. Any model whose average AUC =0.9 for all labels, is a good model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Analysis\n",
    "-----------\n",
    "\n",
    "### Data Exploration\n",
    "\n",
    "The files we are considering in this project are train.csv, test.csv, sample_submission.csv\n",
    "\n",
    "Here is a peak into the data sets.\n",
    "\n",
    "<img src=\"images/train_data.png\" width=\"85%\" alt=\"test data\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/test_data.png\" width=\"40%\" alt=\"test data\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/submission_data.png\" width=\"45%\" alt=\"test data\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Visualization\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The total count of training and testing data:\n",
    "\n",
    "| # train_data  | #test_data |     \n",
    "| :- | :- |\n",
    "| 159571 | 153164 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The count of toxic type comments in the training data:\n",
    "\n",
    "| #Training_total | #toxic | #severe_toxic | #obscene | #threat | #insult | #identity_hate |        \n",
    "| :- | :- | :- | :- | :- | :- | :- | :- |\n",
    "| 159571 | 15294 | 1595 | 8449 | 478 | 7877 | 1405 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of comments with atleast one toxic type and with all toxic types. \n",
    "\n",
    "| #atleast_one_toxic_type  | #all_toxic_types - really bad|     \n",
    "| :- | :- |\n",
    "| 16225 | 31 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Correlation among catgories \n",
    "\n",
    "\n",
    "<img src=\"images/Correlation_columns.png\" width=\"65%\" alt=\"test data\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    From the heatmap, there is an high correlation among obscene, insult, toxic comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* length of comment_text:\n",
    "\n",
    "| test/train | mean of comment length | std of comment length|  max of comment length |\n",
    "| :-  | :- | :- | :- | :- |\n",
    "| train | 394.1 | 590.7 | 5000 |\n",
    "| test | 364.9 | 592.5 | 5000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* no of words in comment_text:\n",
    "\n",
    "| test/train | mean of word count | std of word count|  max of word count |\n",
    "| :-  | :- | :- | :- | :- |\n",
    "| train | 69.4 | 104.1 | 2319 |\n",
    "| test | 66.9 | 106.8| 2833 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have text data, we need to consider the following pre-process steps\n",
    "\n",
    "1. handling the empty text - luckily we don't have any empty comments in the given train or test data\n",
    "2. we need to ignore the stop words\n",
    "3. lower case all text\n",
    "4. feature extraction like part of speech, number of hashtags, number of urls, etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [Link to full data analysis notebook](https://www.google.com)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms and Techniques\n",
    "\n",
    "The primary strategy of this project is to compare different model implementations ranging from Machine Learning Models like\n",
    "* Logistic Regression\n",
    "* SVM\n",
    "* LightGBM\n",
    "* XGBoost\n",
    "\n",
    "and deep learning models like\n",
    "\n",
    "* GRU\n",
    "* LSTM\n",
    "* CNN\n",
    "* RNN\n",
    "* Capsule net\n",
    "* other models\n",
    "\n",
    "over different representations of comments like\n",
    "\n",
    "* word2vec (skip-gram)\n",
    "* word2vec - continuous bag of words(CBOW)\n",
    "* Window based co-occurrence matrix\n",
    "* Low dimensional vector - (SVD)\n",
    "* Glove\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model\n",
    "\n",
    "The basic Benchmark model will be using Logistic Regression model on the test representation of using TF-IDF (Term Frequency, Inverse Document Frequency), which will be a term document matrix. It would be nice to see how the Deep Learning Models will better perform over this basic benchmark model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Solution Statement\n",
    "\n",
    "The plan of action to solve this problem involves:\n",
    "\n",
    "* Downloading and analysis the input test data.\n",
    "* Data Preprocessing - fill nulls, clean the comments, dimension reduction, etc  \n",
    "* Using bag_of_words/Glove/WordToVec to encode the comment into a vector representation.\n",
    "* Data Analysis and Feature Engineer to add or delete some features related to the problem domain.\n",
    "* Splitting the training data into train and validation sets.\n",
    "* Creating different Deep Learning models (LSTM, RNN, CNN)and comparing their accuracy.  \n",
    "* Doing parameter tuning to yield better accuracy scores.\n",
    "\n",
    "### Benchmark Model\n",
    "\n",
    "The basic Benchmark model will be using Logistic Regression model on the test representation of using TF-IDF (Term Frequency, Inverse Document Frequency), which will be a term document matrix. It would be nice to see how the Deep Learning Models will better perform over this basic benchmark model.\n",
    "\n",
    "### Project Design\n",
    "\n",
    "The primary strategy of this project is to compare different model implementations ranging from Machine Learning Models like\n",
    "* Logistic Regression\n",
    "* SVM\n",
    "* LightGBM\n",
    "* XGBoost\n",
    "\n",
    "and deep learning models like\n",
    "\n",
    "* GRU\n",
    "* LSTM\n",
    "* CNN\n",
    "* RNN\n",
    "* Capsule net\n",
    "* other models\n",
    "\n",
    "over different representations of comments like\n",
    "\n",
    "* word2vec (skip-gram)\n",
    "* word2vec - continuous bag of words(CBOW)\n",
    "* Window based co-occurrence matrix\n",
    "* Low dimensional vector - (SVD)\n",
    "* Glove\n",
    "\n",
    "In this process the input representation matters a lot, the following pre-processing techniques will be considered.\n",
    "\n",
    "Pre processing:\n",
    "* Capitalization - case insensitivity\n",
    "* Removing stop words - least useful words like 'the', 'and' will be removed\n",
    "* Tokenization - creating separate tokens\n",
    "* Part of speech tagging - to know meaning of word/sentence better\n",
    "* Stemming - to reduce the input corpus. Prefer Lemmatization over stemming\n",
    "* Lemmatization - to reduce the input corpus. It uses dictionary lookup, context of sentence, part of speech.\n",
    "\n",
    "Feature Engineering techniques:\n",
    "* Part of Speech - this would be a great feature in the case of classification as identity threat might consider more nouns. we can also consider the count of different parts of speech as a feature.\n",
    "* We can also try to use Proportion of capitals, Number of unique words, Number of exclamation marks, Number of punctuations, number of emojis, etc\n",
    "\n",
    "We will use PCA (Principle component analysis to extract the most valued components for our problem). This will help in better training by using more relevant feature combinations.\n",
    "\n",
    "We will be leveraging Google Compute Service for GPU enabled instances for this project to run these DNN models faster.\n",
    "\n",
    "This project will be a great exploratory project for different NLP model implementations and comparing their accuracy, time of execution, etc\n",
    "\n",
    "\n",
    "-----------\n",
    "1. [GPU setup instruction](https://github.com/atmc9/GPU-cloud-setup)\n",
    "2. [NLP with deep learning by Stanford](https://www.youtube.com/watch?v=OQQ-W_63UgQ&list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6)\n",
    "3. [Public kernels from Kaggle Competition](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/kernels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:gpu]",
   "language": "python",
   "name": "conda-env-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
